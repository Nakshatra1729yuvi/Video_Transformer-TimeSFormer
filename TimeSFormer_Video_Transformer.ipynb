{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVwXIOFqmZtD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeSFormerConfig():\n",
        "  def __init__(self):\n",
        "    self.in_channels=3\n",
        "    self.embed_dim=768\n",
        "    self.img_size=256\n",
        "    self.patch_size=32\n",
        "    self.num_patch=(self.img_size//self.patch_size)**2\n",
        "    self.dropout=0.1\n",
        "    self.num_heads=4\n",
        "    self.num_frames=10\n",
        "    self.transformer_units=1\n",
        "    self.num_class=10"
      ],
      "metadata": {
        "id": "Y2Ezy2sspF40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEmbedding(nn.Module):\n",
        "  def __init__(self,config:TimeSFormerConfig):\n",
        "    super().__init__()\n",
        "    self.proj=nn.Conv2d(in_channels=config.in_channels,out_channels=config.embed_dim,kernel_size=config.patch_size,stride=config.patch_size)\n",
        "  def forward(self,x):\n",
        "    B,C,T,H,W=x.shape\n",
        "    x=x.transpose(1,2).reshape(B*T,C,H,W)  #B*T,C,H,W\n",
        "    x=self.proj(x).flatten(2)   #B*T,E_D,N\n",
        "    _,E_D,N=x.shape\n",
        "    x=x.reshape(B,T,N,E_D)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "VE8UNNCEofi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FF(nn.Module):\n",
        "  def __init__(self,config:TimeSFormerConfig):\n",
        "    super().__init__()\n",
        "    self.fc1=nn.Linear(config.embed_dim,4*config.embed_dim)\n",
        "    self.fc2=nn.Linear(4*config.embed_dim,config.embed_dim)\n",
        "    self.dropout=nn.Dropout(config.dropout)\n",
        "  def forward(self,x):\n",
        "    return self.dropout(self.fc2(self.dropout(F.gelu(self.fc1(x)))))\n"
      ],
      "metadata": {
        "id": "WgahKSeque-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"For one block: apply temporal attention then spatial attention (or vice versa).\n",
        "   Temporal attention: attend across T for each patch (shape: B*N, T, D)\n",
        "   Spatial attention: attend across patches for each frame (shape: B*T, N, D)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "4O2E8mR67QFg",
        "outputId": "4ba50829-b1e2-4f97-a131-8414e9564c3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'For one block: apply temporal attention then spatial attention (or vice versa).\\n   Temporal attention: attend across T for each patch (shape: B*N, T, D)\\n   Spatial attention: attend across patches for each frame (shape: B*T, N, D)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DivideSpaceTimeBlock(nn.Module):\n",
        "  def __init__(self,config:TimeSFormerConfig):\n",
        "    super().__init__()\n",
        "    self.ln1=nn.LayerNorm(config.embed_dim)\n",
        "    self.ln2=nn.LayerNorm(config.embed_dim)\n",
        "    self.ln3=nn.LayerNorm(config.embed_dim)\n",
        "    self.temp_attn=nn.MultiheadAttention(embed_dim=config.embed_dim,num_heads=config.num_heads,dropout=config.dropout,batch_first=True)\n",
        "    self.spat_attn=nn.MultiheadAttention(embed_dim=config.embed_dim,num_heads=config.num_heads,dropout=config.dropout,batch_first=True)\n",
        "    self.ff=FF(config)\n",
        "    self.dropout=nn.Dropout(config.dropout)\n",
        "  def forward(self,x,cls_token):\n",
        "    B,T,N,D=x.shape\n",
        "\n",
        "    #Temporal Attn\n",
        "\n",
        "    xt=x.transpose(1,2).contiguous().view(B*N,T,D)\n",
        "    xt=self.ln1(xt)\n",
        "\n",
        "    temp_attn_out,_=self.temp_attn(xt,xt,xt)\n",
        "    xt=self.dropout(temp_attn_out)\n",
        "    xt=xt+temp_attn_out\n",
        "\n",
        "    xt=xt.view(B,N,T,D).transpose(1,2)\n",
        "\n",
        "    x=x+xt\n",
        "\n",
        "    #Spatial Attn\n",
        "\n",
        "    xs=x.view(B*T,N,D)\n",
        "    cls_rep=cls_token.unsqueeze(1).expand(B,1,D).repeat(1,T,1).view(B*T,1,D)\n",
        "    seq=torch.cat((cls_rep,xs),dim=1)\n",
        "    seq_norm=self.ln2(seq)\n",
        "    attn_spat_out,_=self.spat_attn(seq_norm,seq_norm,seq_norm)\n",
        "    seq=seq+self.dropout(attn_spat_out)\n",
        "\n",
        "    cls_token=seq[:,0,:].view(B,T,D)\n",
        "    patch_out=seq[:,1:,:].view(B,T,N,D)\n",
        "    x=patch_out+x\n",
        "\n",
        "    x_flat=x.view(B*T*N,D)\n",
        "    x_norm=self.ln3(x_flat)\n",
        "    x=self.ff(x).view(B,T,N,D)\n",
        "\n",
        "    return x,cls_token\n",
        "\n"
      ],
      "metadata": {
        "id": "QwT2BCwUPYuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeSFormer(nn.Module):\n",
        "  def __init__(self,config:TimeSFormerConfig):\n",
        "    super().__init__()\n",
        "    self.patch_embed=PatchEmbedding(config)\n",
        "    self.cls_token=nn.Parameter(torch.randn(1,config.embed_dim))\n",
        "    self.pos_emb=nn.Parameter(torch.randn(1,config.num_frames,config.embed_dim))\n",
        "    self.dropout=nn.Dropout(config.dropout)\n",
        "    self.blocks=nn.ModuleList([DivideSpaceTimeBlock(config) for _ in range(config.transformer_units)])\n",
        "    self.ln=nn.LayerNorm(config.embed_dim)\n",
        "    self.head=nn.Linear(config.embed_dim,config.num_class)\n",
        "    self.__init_weights()\n",
        "\n",
        "  def __init_weights(self):\n",
        "    nn.init.trunc_normal_(self.pos_emb,std=0.2)\n",
        "    nn.init.trunc_normal_(self.cls_token,std=0.2)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    B,C,T,H,W=x.shape\n",
        "    x=self.patch_embed(x)\n",
        "    B,T,N,D=x.shape\n",
        "    cls_token=self.cls_token.expand(B,D)\n",
        "    print(cls_token.shape)\n",
        "\n",
        "    x=x+self.pos_emb.unsqueeze(2)\n",
        "    x=self.dropout(x)\n",
        "\n",
        "    for block in self.blocks:\n",
        "      x,cls_per_frame=block(x,cls_token)\n",
        "      cls_token=cls_per_frame.mean(dim=1,keepdim=True)\n",
        "      cls_token=cls_token.squeeze(1)\n",
        "\n",
        "\n",
        "    cls=self.ln(cls_token)\n",
        "    out=self.head(cls)\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "qKH_BodCScxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=TimeSFormer(TimeSFormerConfig())\n",
        "t=torch.randn([32,3,10,256,256])\n",
        "out=model(t)\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTGV8pcZrROQ",
        "outputId": "b0dae2d9-424f-49d7-82f0-b4d80dfbecf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 768])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}